{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the transcripts generated with automatic speech recognition.\n",
    "\n",
    "In this notebook, we try to compare manual transcripts with the transcripts automatically generated using vosk.\n",
    "\n",
    "Those transcripts can be found in the [Transcripts](Transcripts/) folder. They are named after the person being interviewed. For each person, only the first 12 minutes of the audio record have been transcribed using vosk. So we have to take into account only the text corresponding to the first 12 minutes of audio in the manual transcripts. To do so, we search manually the last word being said after 12 minutes and take note of total number of caracters from the begining till the end of the last word. We then cut off the rest of the text in the `comparison()` function (see code below for more details).\n",
    "\n",
    "Transcripts written manually:\n",
    "- [alexis.docx](Transcripts/alexis.docx)\n",
    "- [caitlyn.docx](Transcripts/caitlyn.docx)\n",
    "- [clement1.docx](Transcripts/clement1.docx)\n",
    "- [clement2.docx](Transcripts/clement2.docx)\n",
    "\n",
    "Transcripts automatically generated with vosk:\n",
    "- [vosk_alexis.txt](Transcripts/vosk_alexis.txt)\n",
    "- [vosk_caitlyn.txt](Transcripts/vosk_caitlyn.txt)\n",
    "- [vosk_clement1.txt](Transcripts/vosk_clement1.txt)\n",
    "- [vosk_clement2.txt](Transcripts/vosk_clement2.txt)\n",
    "\n",
    "When comparing two corresponding texts, the first thing we notice is that the vosk transcripts do not contain any punctuation, capital letters or paragraphs, whereas the human transcripts contains punctuation, some onomatopoeias which are not in the vosk transcripts (such as \"humm\"), and a special syntax with \"#\" at the beginning and at the end of some paragraphs to indicate that the interviewer is speaking. Another difference is that the numbers in are written in full letters in the vosk transcripts, and with digits in the human transcript. Of course, in addition to these differences there are some errors of transcription\n",
    "\n",
    "Those differences complicate the comparison between the transcripts. The best thing to do would be to find a way to automatically add punctuation to the vosk transcripts. But this being quite hard to do, we decided to (automatically) remove the punctuation from the human transcript, remove the \"#\", the line breaks (marked as \"\\n\"), as well as remove some onomatopeas (\"humm\") and convert digit numbers to written letters. All this is done in the `remove_punctuation()` function. We get simplified manual transcripts.\n",
    "\n",
    "Once this is done, the simplified manual transcripts are considered as the ground truth and we compute the word error rate (`'wer'`) for the vosk transcripts in the `comparison()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alexis': {'wer': 0.36015006252605253,\n",
       "  'mer': 0.35717238528317485,\n",
       "  'wil': 0.5027477120564747,\n",
       "  'wip': 0.4972522879435252,\n",
       "  'hits': 1555,\n",
       "  'substitutions': 452,\n",
       "  'deletions': 392,\n",
       "  'insertions': 20},\n",
       " 'caitlyn': {'wer': 0.3766914011348756,\n",
       "  'mer': 0.3673903788846318,\n",
       "  'wil': 0.537274685032102,\n",
       "  'wip': 0.4627253149678981,\n",
       "  'hits': 1486,\n",
       "  'substitutions': 539,\n",
       "  'deletions': 266,\n",
       "  'insertions': 58},\n",
       " 'clement1': {'wer': 0.457033125300048,\n",
       "  'mer': 0.4469483568075117,\n",
       "  'wil': 0.6246789232756114,\n",
       "  'wip': 0.3753210767243886,\n",
       "  'hits': 1178,\n",
       "  'substitutions': 550,\n",
       "  'deletions': 355,\n",
       "  'insertions': 47},\n",
       " 'clement2': {'wer': 0.4313960455362493,\n",
       "  'mer': 0.42328042328042326,\n",
       "  'wil': 0.594222838202449,\n",
       "  'wip': 0.405777161797551,\n",
       "  'hits': 981,\n",
       "  'substitutions': 408,\n",
       "  'deletions': 280,\n",
       "  'insertions': 32}}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jiwer\n",
    "import docx\n",
    "import jiwer\n",
    "import num2words\n",
    "\n",
    "# get_text() converts the manual transcript docx files to a python string.\n",
    "def get_text(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)  # type: str\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuations = \".,?!#:;°\"  # punctuation marks to be removed\n",
    "    clean_txt = \"\"\n",
    "    for char in text:\n",
    "        if char not in punctuations:\n",
    "            clean_txt += char\n",
    "\n",
    "    clean_txt = clean_txt.lower()  # Capital letters replaced with lower case\n",
    "    clean_txt = clean_txt.replace(\"\\xa0\", \"\")  # Remove non-breaking spaces\n",
    "    clean_txt = clean_txt.replace(\" \\n \", \" \")  # Remove line breaks\n",
    "    clean_txt = clean_txt.replace(\"\\n\", \"\")\n",
    "    clean_txt = clean_txt.replace(\" humm \", \" \")  # Remove \"humm\"\n",
    "    clean_txt = clean_txt.replace(\"’\", \"'\")  # Apostrophes are different (’ vs ')\n",
    "\n",
    "    # We check each word seperatly to see if it is a number written in digits.\n",
    "    # If it is a digit number we replace it with the matching number in letters.\n",
    "    for word in str.split(clean_txt):\n",
    "        if word.isdigit():\n",
    "            len_word = len(word)\n",
    "            number_word = num2words.num2words(int(word), lang='fr')\n",
    "            pos = clean_txt.find(word)\n",
    "            clean_txt = clean_txt[:pos] + number_word + clean_txt[pos+len_word:]  \n",
    "\n",
    "    # num2words doesn't write 21 correctly so we correct it.\n",
    "    clean_txt = clean_txt.replace(\"vingt et un\", \"vingt-et-un\")\n",
    "\n",
    "    return clean_txt\n",
    "\n",
    "# The names used to identify the 4 pairs of transcripts studied.\n",
    "list_names = [\"alexis\", \n",
    "              \"caitlyn\",\n",
    "              \"clement1\",\n",
    "              \"clement2\"]\n",
    "\n",
    "# Number of caracters in the manual transcripts corresponding to the first 12 min\n",
    "# of audio. This has been determined manually.\n",
    "stop_12_min = {\"alexis\": 12313, \n",
    "               \"caitlyn\" : 12033,\n",
    "               \"clement1\" : 10786,\n",
    "               \"clement2\" : 8753}\n",
    "\n",
    "# We comptute the WER for a vosk transcript and other types of error mesures\n",
    "# in the comparison() function using the jiwer library.\n",
    "def comparison(name):\n",
    "    path_to_transcript = \"transcripts/\" + str(name) + \".docx\"\n",
    "    text = get_text(path_to_transcript)  # manual transcription\n",
    "    clean_text = remove_punctuation(text)  # simplified manual transcrition\n",
    "    clean_text = clean_text[:stop_12_min[name]]  # first 12 minutes in transcript\n",
    "    vosk_file = open('transcripts/vosk_' + name + '.txt','r')\n",
    "    vosk_text = vosk_file.read()  # vosk transcription\n",
    "    result = jiwer.compute_measures(clean_text, vosk_text)  # computes WER...\n",
    "    return result\n",
    "\n",
    "# We compute the errors mesures for all the 4 transcriptions.\n",
    "error_mesures = {}\n",
    "for name in list_names:\n",
    "    error_mesures[name] = comparison(name)\n",
    "    \n",
    "error_mesures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the reults in a json file (see [error_mesures.json](Transcripts/error_mesures.json)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"error_mesures.json\", \"w\") as outfile:  \n",
    "    json.dump(error_mesures, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better read the result we display it as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alexis</th>\n",
       "      <th>caitlyn</th>\n",
       "      <th>clement1</th>\n",
       "      <th>clement2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wer</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mer</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wil</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wip</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hits</th>\n",
       "      <td>1555.00</td>\n",
       "      <td>1486.00</td>\n",
       "      <td>1178.00</td>\n",
       "      <td>981.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substitutions</th>\n",
       "      <td>452.00</td>\n",
       "      <td>539.00</td>\n",
       "      <td>550.00</td>\n",
       "      <td>408.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deletions</th>\n",
       "      <td>392.00</td>\n",
       "      <td>266.00</td>\n",
       "      <td>355.00</td>\n",
       "      <td>280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insertions</th>\n",
       "      <td>20.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                alexis  caitlyn  clement1  clement2\n",
       "wer               0.36     0.38      0.46      0.43\n",
       "mer               0.36     0.37      0.45      0.42\n",
       "wil               0.50     0.54      0.62      0.59\n",
       "wip               0.50     0.46      0.38      0.41\n",
       "hits           1555.00  1486.00   1178.00    981.00\n",
       "substitutions   452.00   539.00    550.00    408.00\n",
       "deletions       392.00   266.00    355.00    280.00\n",
       "insertions       20.00    58.00     47.00     32.00"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(error_mesures).round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bar chart to compare the word error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8770fbee50>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as pyplot\n",
    "\n",
    "names = []\n",
    "wer = []\n",
    "\n",
    "for name in error_mesures:\n",
    "    names.append(name)\n",
    "    wer.append(error_mesures[name][\"wer\"])\n",
    "mean_wer = np.mean(wer)\n",
    "\n",
    "plt.bar(names,wer)\n",
    "plt.axhline(mean_wer, color=\"red\", label=\"average = \" + str(mean_wer.round(2)))\n",
    "plt.grid(axis='y')\n",
    "plt.ylabel(\"WER\")\n",
    "plt.title(\"Word Error Rates\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WER is around 0.4 which is not so good. When we read the text, we notice indeed that there are still too many errors to really understand what is being said.\n",
    "\n",
    "In comparison, for the \"common voice\" corpus the vosk model is claimed to have a wer of 0.16. This can be explained by the fact that in our corpus we have spontaneous speech instead of text that is read which is the case of the \"common voice\" corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
